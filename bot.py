import os
import json
import asyncio
import speech_recognition as sr
from aiogram import Bot, Dispatcher, types
from aiogram.contrib.fsm_storage.memory import MemoryStorage
from aiogram.utils import executor
from deep_translator import GoogleTranslator
from pydub import AudioSegment

API_TOKEN = "8270631879:AAEXhJ9G_5PPLUUSiqYBgnRpZZ3RNlAp0kY"

# Ø³Ø§Ø®Øª Ø±Ø¨Ø§Øª
bot = Bot(token=API_TOKEN)
dp = Dispatcher(bot, storage=MemoryStorage())

# Ø°Ø®ÛŒØ±Ù‡ Ø²Ø¨Ø§Ù† Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
USER_LANGS_FILE = "user_langs.json"
LANG_OPTIONS = {
    "ğŸ‡¬ğŸ‡§ English": "en",
    "ğŸ‡®ğŸ‡· ÙØ§Ø±Ø³ÛŒ": "fa",
    "ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e": "tr",
    "ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹": "ru",
    "ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": "ar",
    "ğŸ‡ªğŸ‡¸ EspaÃ±ol": "es",
    "ğŸ‡«ğŸ‡· FranÃ§ais": "fr",
}

# ---------- Ù…Ø¯ÛŒØ±ÛŒØª ÙØ§ÛŒÙ„ Ø²Ø¨Ø§Ù† ----------
def load_user_langs():
    if os.path.exists(USER_LANGS_FILE):
        with open(USER_LANGS_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

def save_user_langs(data):
    with open(USER_LANGS_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

user_langs = load_user_langs()


# ---------- Ø§Ø³ØªØ§Ø±Øª ----------
@dp.message_handler(commands=["start"])
async def command_start(message: types.Message):
    keyboard = types.ReplyKeyboardMarkup(resize_keyboard=True)
    for lang in LANG_OPTIONS.keys():
        keyboard.add(lang)
    await message.answer("Ø³Ù„Ø§Ù…! ğŸŒ Ù„Ø·ÙØ§ Ø²Ø¨Ø§Ù† Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø®ÙˆØ¯ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:", reply_markup=keyboard)


# ---------- Ø§Ù†ØªØ®Ø§Ø¨ Ø²Ø¨Ø§Ù† ----------
@dp.message_handler(lambda msg: msg.text in LANG_OPTIONS.keys())
async def set_language(message: types.Message):
    user_id = str(message.from_user.id)
    user_langs[user_id] = LANG_OPTIONS[message.text]
    save_user_langs(user_langs)
    await message.answer(f"Ø²Ø¨Ø§Ù† Ø´Ù…Ø§ ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯: {message.text}", reply_markup=types.ReplyKeyboardRemove())


# ---------- ØªØ±Ø¬Ù…Ù‡ Ù…ØªÙ† ----------
@dp.message_handler(content_types=["text"])
async def translate_text(message: types.Message):
    user_id = str(message.from_user.id)
    target_lang = user_langs.get(user_id, "en")

    try:
        translated = GoogleTranslator(source="auto", target=target_lang).translate(message.text)
        await message.reply(translated)
    except Exception as e:
        await message.reply(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ±Ø¬Ù…Ù‡: {e}")


# ---------- ØªØ±Ø¬Ù…Ù‡ ÙˆÛŒØ³ ----------
@dp.message_handler(content_types=["voice"])
async def voice_translator(message: types.Message):
    user_id = str(message.from_user.id)
    target_lang = user_langs.get(user_id, "en")

    file = await bot.get_file(message.voice.file_id)
    ogg_path = f"voice_{user_id}.ogg"
    wav_path = f"voice_{user_id}.wav"

    await bot.download_file(file.file_path, destination=ogg_path)

    # ØªØ¨Ø¯ÛŒÙ„ ogg Ø¨Ù‡ wav
    AudioSegment.from_file(ogg_path, format="ogg").export(wav_path, format="wav")

    recognizer = sr.Recognizer()
    try:
        with sr.AudioFile(wav_path) as src:
            audio = recognizer.record(src)
            text = recognizer.recognize_google(audio, language="auto")

            translated = GoogleTranslator(source="auto", target=target_lang).translate(text)
            await message.reply(translated)

    except Exception as e:
        await message.reply(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙˆÛŒØ³: {e}")

    finally:
        if os.path.exists(ogg_path):
            os.remove(ogg_path)
        if os.path.exists(wav_path):
            os.remove(wav_path)


# ---------- Ø±Ø§Ù† Ú©Ø±Ø¯Ù† Ø±Ø¨Ø§Øª ----------
if name == "__main__":
    executor.start_polling(dp, skip_updates=True)
